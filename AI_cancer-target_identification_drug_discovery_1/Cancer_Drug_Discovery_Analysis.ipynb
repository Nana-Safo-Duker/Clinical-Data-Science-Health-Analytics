{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI-Driven Cancer Target Identification and Drug Discovery\n",
        "\n",
        "## Comprehensive Analysis Workflow\n",
        "\n",
        "This notebook demonstrates key computational approaches for cancer target identification and drug discovery, including:\n",
        "- Statistical analysis (t-tests, ANOVA)\n",
        "- Dimensionality reduction (PCA, t-SNE, UMAP)\n",
        "- Machine learning models for drug response prediction\n",
        "- Network analysis for protein-protein interactions\n",
        "- Multi-omics data integration\n",
        "\n",
        "**Reference Paper**: Signal Transduction and Targeted Therapy - https://www.nature.com/articles/s41392-022-00994-0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core data science libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, \n",
        "                            roc_auc_score, accuracy_score, roc_curve)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Dimensionality reduction\n",
        "from sklearn.manifold import TSNE\n",
        "import umap.umap_ as umap\n",
        "\n",
        "# Statistical analysis\n",
        "from scipy import stats\n",
        "from scipy.stats import ttest_ind, f_oneway\n",
        "import pingouin as pg\n",
        "\n",
        "# Network analysis\n",
        "import networkx as nx\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generate Synthetic Gene Expression Data\n",
        "\n",
        "Since we don't have access to real TCGA data, we'll generate synthetic but realistic gene expression data that mimics cancer vs normal samples. This demonstrates key analysis workflows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Parameters\n",
        "n_genes = 200  # Number of genes in our analysis\n",
        "n_cancer_samples = 100\n",
        "n_normal_samples = 100\n",
        "n_differential_genes = 50  # Genes that are differentially expressed\n",
        "\n",
        "# Generate gene names\n",
        "gene_names = [f\"Gene_{i+1}\" for i in range(n_genes)]\n",
        "\n",
        "# Generate synthetic data\n",
        "# Normal samples: baseline expression with some variation\n",
        "normal_data = np.random.normal(loc=5.0, scale=1.5, size=(n_normal_samples, n_genes))\n",
        "\n",
        "# Cancer samples: some genes are upregulated, some downregulated\n",
        "cancer_data = np.random.normal(loc=5.0, scale=1.5, size=(n_cancer_samples, n_genes))\n",
        "\n",
        "# Create differential expression\n",
        "differential_indices = np.random.choice(n_genes, n_differential_genes, replace=False)\n",
        "\n",
        "for idx in differential_indices[:n_differential_genes//2]:\n",
        "    # Upregulated genes\n",
        "    cancer_data[:, idx] = np.random.normal(loc=8.0, scale=2.0, size=n_cancer_samples)\n",
        "\n",
        "for idx in differential_indices[n_differential_genes//2:]:\n",
        "    # Downregulated genes\n",
        "    cancer_data[:, idx] = np.random.normal(loc=2.0, scale=1.0, size=n_cancer_samples)\n",
        "\n",
        "# Combine data\n",
        "data = np.vstack([normal_data, cancer_data])\n",
        "\n",
        "# Create labels\n",
        "labels = np.array(['Normal'] * n_normal_samples + ['Cancer'] * n_cancer_samples)\n",
        "\n",
        "# Create DataFrame\n",
        "df_gene_exp = pd.DataFrame(data, columns=gene_names)\n",
        "df_gene_exp['Sample_Type'] = labels\n",
        "\n",
        "print(f\"Generated synthetic data:\")\n",
        "print(f\"  - Total samples: {len(df_gene_exp)}\")\n",
        "print(f\"  - Normal samples: {n_normal_samples}\")\n",
        "print(f\"  - Cancer samples: {n_cancer_samples}\")\n",
        "print(f\"  - Genes analyzed: {n_genes}\")\n",
        "print(f\"  - Differentially expressed: {n_differential_genes}\")\n",
        "print(f\"\\nData shape: {df_gene_exp.shape}\")\n",
        "df_gene_exp.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Statistical Analysis: T-tests for Differential Expression\n",
        "\n",
        "T-tests compare means between groups and are fundamental for identifying significantly differentially expressed genes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform t-tests for each gene\n",
        "t_test_results = []\n",
        "\n",
        "for gene in gene_names:\n",
        "    normal_exp = df_gene_exp[df_gene_exp['Sample_Type'] == 'Normal'][gene]\n",
        "    cancer_exp = df_gene_exp[df_gene_exp['Sample_Type'] == 'Cancer'][gene]\n",
        "    \n",
        "    # Perform t-test\n",
        "    t_stat, p_value = ttest_ind(normal_exp, cancer_exp)\n",
        "    \n",
        "    # Calculate effect size (Cohen's d)\n",
        "    mean_diff = cancer_exp.mean() - normal_exp.mean()\n",
        "    pooled_std = np.sqrt((normal_exp.std()**2 + cancer_exp.std()**2) / 2)\n",
        "    cohens_d = mean_diff / pooled_std\n",
        "    \n",
        "    t_test_results.append({\n",
        "        'Gene': gene,\n",
        "        'Mean_Normal': normal_exp.mean(),\n",
        "        'Mean_Cancer': cancer_exp.mean(),\n",
        "        'Mean_Difference': mean_diff,\n",
        "        'T_Statistic': t_stat,\n",
        "        'P_Value': p_value,\n",
        "        'Cohen_D': cohens_d,\n",
        "        'Std_Normal': normal_exp.std(),\n",
        "        'Std_Cancer': cancer_exp.std()\n",
        "    })\n",
        "\n",
        "# Create results DataFrame\n",
        "df_tests = pd.DataFrame(t_test_results)\n",
        "\n",
        "# Add significance markers\n",
        "df_tests['Significant'] = df_tests['P_Value'] < 0.05\n",
        "df_tests['FDR_Corrected'] = False\n",
        "\n",
        "# Multiple testing correction (Bonferroni)\n",
        "num_comparisons = len(df_tests)\n",
        "df_tests.loc[df_tests['P_Value'] < 0.05/num_comparisons, 'FDR_Corrected'] = True\n",
        "\n",
        "# Sort by P-value\n",
        "df_tests = df_tests.sort_values('P_Value')\n",
        "\n",
        "print(f\"T-test Results Summary:\")\n",
        "print(f\"Significant genes (p < 0.05): {df_tests['Significant'].sum()} out of {len(df_tests)}\")\n",
        "print(f\"Significant after Bonferroni correction: {df_tests['FDR_Corrected'].sum()}\")\n",
        "\n",
        "# Display top results\n",
        "print(\"\\nTop 10 Most Significantly Differentially Expressed Genes:\")\n",
        "display(df_tests.head(10)[['Gene', 'Mean_Normal', 'Mean_Cancer', 'Mean_Difference', \n",
        "                            'P_Value', 'Cohen_D', 'Significant']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize t-test results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. P-value distribution\n",
        "axes[0, 0].hist(df_tests['P_Value'], bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "axes[0, 0].axvline(0.05, color='red', linestyle='--', label='p = 0.05 threshold')\n",
        "axes[0, 0].set_xlabel('P-Value', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0, 0].set_title('Distribution of P-Values from T-tests', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# 2. Volcano plot\n",
        "sig_threshold = 0.05\n",
        "fold_change = df_tests['Mean_Difference']\n",
        "log_p_values = -np.log10(df_tests['P_Value'])\n",
        "\n",
        "colors = ['red' if (p < sig_threshold and abs(fc) > 1) else 'gray' \n",
        "          for p, fc in zip(df_tests['P_Value'], fold_change)]\n",
        "\n",
        "axes[0, 1].scatter(fold_change, log_p_values, c=colors, alpha=0.6, s=30)\n",
        "axes[0, 1].axhline(-np.log10(sig_threshold), color='red', linestyle='--', label='p = 0.05')\n",
        "axes[0, 1].axvline(-1, color='blue', linestyle='--', alpha=0.5)\n",
        "axes[0, 1].axvline(1, color='blue', linestyle='--', alpha=0.5)\n",
        "axes[0, 1].set_xlabel('Mean Difference (Cancer - Normal)', fontsize=12)\n",
        "axes[0, 1].set_ylabel('-log10(P-Value)', fontsize=12)\n",
        "axes[0, 1].set_title('Volcano Plot: Differential Gene Expression', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# 3. Effect sizes (Cohen's d)\n",
        "sig_genes = df_tests[df_tests['Significant']]\n",
        "axes[1, 0].barh(range(min(20, len(sig_genes))), \n",
        "                sig_genes.head(20).sort_values('Cohen_D', ascending=True)['Cohen_D'],\n",
        "                color='coral', alpha=0.8, edgecolor='black')\n",
        "axes[1, 0].set_yticks(range(min(20, len(sig_genes))))\n",
        "axes[1, 0].set_yticklabels(sig_genes.head(20).sort_values('Cohen_D', ascending=True)['Gene'], fontsize=8)\n",
        "axes[1, 0].set_xlabel(\"Cohen's d (Effect Size)\", fontsize=12)\n",
        "axes[1, 0].set_title('Top 20 Genes by Effect Size', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].axvline(0, color='black', linestyle='-', linewidth=0.5)\n",
        "axes[1, 0].grid(alpha=0.3, axis='x')\n",
        "\n",
        "# 4. Summary statistics\n",
        "summary_data = pd.DataFrame({\n",
        "    'Statistic': ['Mean', 'Median', 'Std', 'Min', 'Max'],\n",
        "    'P_Value': [df_tests['P_Value'].mean(), df_tests['P_Value'].median(), \n",
        "                df_tests['P_Value'].std(), df_tests['P_Value'].min(), \n",
        "                df_tests['P_Value'].max()]\n",
        "})\n",
        "\n",
        "axes[1, 1].axis('tight')\n",
        "axes[1, 1].axis('off')\n",
        "table = axes[1, 1].table(cellText=summary_data.values,\n",
        "                         colLabels=summary_data.columns,\n",
        "                         cellLoc='center',\n",
        "                         loc='center',\n",
        "                         bbox=[0, 0, 1, 1])\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(11)\n",
        "table.scale(1, 2)\n",
        "axes[1, 1].set_title('P-Value Summary Statistics', fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nStatistical analysis complete!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Dimensionality Reduction: PCA, t-SNE, and UMAP\n",
        "\n",
        "Dimensionality reduction is crucial for visualizing and understanding high-dimensional omics data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for dimensionality reduction\n",
        "X = df_gene_exp.drop('Sample_Type', axis=1).values\n",
        "y = df_gene_exp['Sample_Type'].values\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 1. PCA - Linear dimensionality reduction\n",
        "print(\"Performing PCA...\")\n",
        "pca = PCA(n_components=min(50, X_scaled.shape[1]))\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Calculate explained variance\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "cumulative_variance = np.cumsum(explained_variance)\n",
        "\n",
        "print(f\"PCA: First 10 components explain {cumulative_variance[9]:.2%} of variance\")\n",
        "print(f\"PCA: First 20 components explain {cumulative_variance[19]:.2%} of variance\")\n",
        "\n",
        "# 2. t-SNE - Non-linear dimensionality reduction\n",
        "print(\"\\nPerforming t-SNE (this may take a moment)...\")\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
        "X_tsne = tsne.fit_transform(X_scaled)\n",
        "print(\"t-SNE complete!\")\n",
        "\n",
        "# 3. UMAP - Non-linear dimensionality reduction\n",
        "print(\"\\nPerforming UMAP...\")\n",
        "umap_reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
        "X_umap = umap_reducer.fit_transform(X_scaled)\n",
        "print(\"UMAP complete!\")\n",
        "\n",
        "print(\"\\nDimensionality reduction complete!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize dimensionality reduction results\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Color mapping\n",
        "colors = {'Normal': 'steelblue', 'Cancer': 'crimson'}\n",
        "sample_colors = [colors[label] for label in y]\n",
        "\n",
        "# PCA plots\n",
        "# 1. Explained variance\n",
        "axes[0, 0].bar(range(1, 21), explained_variance[:20], alpha=0.7, color='teal', edgecolor='black')\n",
        "axes[0, 0].plot(range(1, 21), cumulative_variance[:20], 'ro-', markersize=6, label='Cumulative')\n",
        "axes[0, 0].axhline(0.95, color='red', linestyle='--', alpha=0.5, label='95% variance')\n",
        "axes[0, 0].set_xlabel('Principal Component', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Explained Variance Ratio', fontsize=12)\n",
        "axes[0, 0].set_title('PCA: Explained Variance by Component', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# 2. PCA scatter plot\n",
        "scatter1 = axes[0, 1].scatter(X_pca[:, 0], X_pca[:, 1], c=sample_colors, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
        "axes[0, 1].set_xlabel(f'PC1 ({explained_variance[0]:.2%} variance)', fontsize=12)\n",
        "axes[0, 1].set_ylabel(f'PC2 ({explained_variance[1]:.2%} variance)', fontsize=12)\n",
        "axes[0, 1].set_title('PCA: First Two Components', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "# Add legend\n",
        "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors[label], \n",
        "                               markersize=10, label=label) for label in ['Normal', 'Cancer']]\n",
        "axes[0, 1].legend(handles=legend_elements, loc='best')\n",
        "\n",
        "# 3. PCA components 3 and 4\n",
        "scatter3 = axes[0, 2].scatter(X_pca[:, 2], X_pca[:, 3], c=sample_colors, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
        "axes[0, 2].set_xlabel(f'PC3 ({explained_variance[2]:.2%} variance)', fontsize=12)\n",
        "axes[0, 2].set_ylabel(f'PC4 ({explained_variance[3]:.2%} variance)', fontsize=12)\n",
        "axes[0, 2].set_title('PCA: Components 3 and 4', fontsize=14, fontweight='bold')\n",
        "axes[0, 2].grid(alpha=0.3)\n",
        "axes[0, 2].legend(handles=legend_elements, loc='best')\n",
        "\n",
        "# t-SNE plot\n",
        "scatter2 = axes[1, 0].scatter(X_tsne[:, 0], X_tsne[:, 1], c=sample_colors, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
        "axes[1, 0].set_xlabel('t-SNE 1', fontsize=12)\n",
        "axes[1, 0].set_ylabel('t-SNE 2', fontsize=12)\n",
        "axes[1, 0].set_title('t-SNE Visualization', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "axes[1, 0].legend(handles=legend_elements, loc='best')\n",
        "\n",
        "# UMAP plot\n",
        "scatter4 = axes[1, 1].scatter(X_umap[:, 0], X_umap[:, 1], c=sample_colors, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
        "axes[1, 1].set_xlabel('UMAP 1', fontsize=12)\n",
        "axes[1, 1].set_ylabel('UMAP 2', fontsize=12)\n",
        "axes[1, 1].set_title('UMAP Visualization', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "axes[1, 1].legend(handles=legend_elements, loc='best')\n",
        "\n",
        "# Comparison text\n",
        "axes[1, 2].axis('off')\n",
        "comparison_text = '''\n",
        "Dimensionality Reduction Comparison:\n",
        "\n",
        "PCA (Principal Component Analysis):\n",
        "• Linear transformation\n",
        "• Preserves global structure\n",
        "• Interpretable components\n",
        "• Fast computation\n",
        "\n",
        "t-SNE:\n",
        "• Non-linear transformation\n",
        "• Preserves local neighborhoods\n",
        "• Good for visualization\n",
        "• Computationally intensive\n",
        "\n",
        "UMAP:\n",
        "• Non-linear transformation\n",
        "• Preserves local & global structure\n",
        "• Fast and scalable\n",
        "• Good for both visualization and ML\n",
        "'''\n",
        "axes[1, 2].text(0.1, 0.5, comparison_text, fontsize=12, family='monospace',\n",
        "                verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nVisualization complete!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Machine Learning Models for Drug Response Prediction\n",
        "\n",
        "We'll train multiple ML models to predict cancer vs normal samples, simulating drug response prediction using gene expression features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for ML\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"Features: {X_train.shape[1]}\")\n",
        "\n",
        "# Train multiple models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, C=1.0),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42, max_depth=5),\n",
        "    'Neural Network': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    \n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Evaluate\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    \n",
        "    # Cross-validation score\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    \n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'accuracy': accuracy,\n",
        "        'auc': auc,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    }\n",
        "    \n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  AUC-ROC: {auc:.4f}\")\n",
        "    print(f\"  CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "\n",
        "print(\"\\nModel training complete!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
        "\n",
        "# 1. Model comparison bar plot\n",
        "model_names = list(results.keys())\n",
        "accuracies = [results[m]['accuracy'] for m in model_names]\n",
        "aucs = [results[m]['auc'] for m in model_names]\n",
        "\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.35\n",
        "\n",
        "axes[0, 0].bar(x - width/2, accuracies, width, label='Accuracy', color='steelblue', alpha=0.8, edgecolor='black')\n",
        "axes[0, 0].bar(x + width/2, aucs, width, label='AUC-ROC', color='crimson', alpha=0.8, edgecolor='black')\n",
        "axes[0, 0].set_ylabel('Score', fontsize=12)\n",
        "axes[0, 0].set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xticks(x)\n",
        "axes[0, 0].set_xticklabels(model_names, rotation=45, ha='right', fontsize=10)\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3, axis='y')\n",
        "axes[0, 0].set_ylim([0.5, 1.0])\n",
        "\n",
        "# 2. ROC curves for all models\n",
        "for name, result in results.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, result['y_pred_proba'])\n",
        "    axes[0, 1].plot(fpr, tpr, label=f'{name} (AUC={result[\"auc\"]:.3f})', linewidth=2)\n",
        "\n",
        "axes[0, 1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "axes[0, 1].set_xlabel('False Positive Rate', fontsize=12)\n",
        "axes[0, 1].set_ylabel('True Positive Rate', fontsize=12)\n",
        "axes[0, 1].set_title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# 3. Confusion matrices for top 2 models\n",
        "# Sort by AUC\n",
        "sorted_models = sorted(results.items(), key=lambda x: x[1]['auc'], reverse=True)\n",
        "\n",
        "for idx, (name, result) in enumerate(sorted_models[:2]):\n",
        "    cm = confusion_matrix(y_test, result['y_pred'])\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, idx], \n",
        "                cbar_kws={'label': 'Count'}, square=True, linewidths=1, linecolor='black')\n",
        "    axes[1, idx].set_xlabel('Predicted', fontsize=12)\n",
        "    axes[1, idx].set_ylabel('Actual', fontsize=12)\n",
        "    axes[1, idx].set_title(f'{name}\\nConfusion Matrix', fontsize=12, fontweight='bold')\n",
        "    axes[1, idx].set_xticklabels(['Normal', 'Cancer'])\n",
        "    axes[1, idx].set_yticklabels(['Normal', 'Cancer'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create results summary table\n",
        "summary_df = pd.DataFrame({\n",
        "    'Model': model_names,\n",
        "    'Accuracy': [results[m]['accuracy'] for m in model_names],\n",
        "    'AUC-ROC': [results[m]['auc'] for m in model_names],\n",
        "    'CV Accuracy (Mean)': [results[m]['cv_mean'] for m in model_names],\n",
        "    'CV Accuracy (Std)': [results[m]['cv_std'] for m in model_names]\n",
        "})\n",
        "\n",
        "print(\"\\nDetailed Results Summary:\")\n",
        "print(\"=\"*80)\n",
        "display(summary_df.round(4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature Importance Analysis\n",
        "\n",
        "Understanding which genes (features) are most important for model predictions provides biological insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract feature importance from tree-based models\n",
        "rf_model = results['Random Forest']['model']\n",
        "gb_model = results['Gradient Boosting']['model']\n",
        "\n",
        "# Get feature importances\n",
        "rf_importance = pd.DataFrame({\n",
        "    'Gene': gene_names,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "gb_importance = pd.DataFrame({\n",
        "    'Gene': gene_names,\n",
        "    'Importance': gb_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "# Visualize top features\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Random Forest\n",
        "top_n = 20\n",
        "axes[0].barh(range(top_n), rf_importance.head(top_n).sort_values('Importance')['Importance'],\n",
        "             color='steelblue', alpha=0.8, edgecolor='black')\n",
        "axes[0].set_yticks(range(top_n))\n",
        "axes[0].set_yticklabels(rf_importance.head(top_n).sort_values('Importance')['Gene'], fontsize=9)\n",
        "axes[0].set_xlabel('Importance', fontsize=12)\n",
        "axes[0].set_title('Random Forest: Top 20 Most Important Genes', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(alpha=0.3, axis='x')\n",
        "axes[0].invert_yaxis()\n",
        "\n",
        "# Gradient Boosting\n",
        "axes[1].barh(range(top_n), gb_importance.head(top_n).sort_values('Importance')['Importance'],\n",
        "             color='crimson', alpha=0.8, edgecolor='black')\n",
        "axes[1].set_yticks(range(top_n))\n",
        "axes[1].set_yticklabels(gb_importance.head(top_n).sort_values('Importance')['Gene'], fontsize=9)\n",
        "axes[1].set_xlabel('Importance', fontsize=12)\n",
        "axes[1].set_title('Gradient Boosting: Top 20 Most Important Genes', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(alpha=0.3, axis='x')\n",
        "axes[1].invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Compare with differential expression results\n",
        "print(\"\\nComparing Feature Importance with Differential Expression:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Find common top features\n",
        "rf_top_genes = set(rf_importance.head(20)['Gene'])\n",
        "gb_top_genes = set(gb_importance.head(20)['Gene'])\n",
        "de_top_genes = set(df_tests.head(20)['Gene'])\n",
        "\n",
        "print(f\"Genes in top 20 of Random Forest: {len(rf_top_genes)}\")\n",
        "print(f\"Genes in top 20 of Gradient Boosting: {len(gb_top_genes)}\")\n",
        "print(f\"Genes in top 20 of differential expression: {len(de_top_genes)}\")\n",
        "print(f\"\\nGenes in both RF and DE top 20: {len(rf_top_genes & de_top_genes)}\")\n",
        "print(f\"Genes in both GB and DE top 20: {len(gb_top_genes & de_top_genes)}\")\n",
        "print(f\"Genes in all three top 20s: {len(rf_top_genes & gb_top_genes & de_top_genes)}\")\n",
        "\n",
        "# Show overlap\n",
        "print(\"\\nCommon important genes across all methods:\")\n",
        "common_genes = rf_top_genes & gb_top_genes & de_top_genes\n",
        "for gene in sorted(common_genes)[:10]:\n",
        "    print(f\"  - {gene}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Conclusion\n",
        "\n",
        "This notebook demonstrated key computational approaches for AI-driven cancer target identification and drug discovery:\n",
        "\n",
        "1. **Statistical Analysis**: T-tests for identifying differentially expressed genes\n",
        "2. **Dimensionality Reduction**: PCA, t-SNE, and UMAP for visualization and feature reduction\n",
        "3. **Machine Learning**: Multiple algorithms for drug response prediction\n",
        "4. **Feature Analysis**: Understanding which genes drive predictions\n",
        "\n",
        "These methods are fundamental to modern precision medicine and drug discovery workflows.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
