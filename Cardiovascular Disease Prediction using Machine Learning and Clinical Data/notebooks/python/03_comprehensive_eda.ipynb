{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook provides a comprehensive exploratory data analysis of the Cardiovascular Disease Dataset, including:\n",
    "- Data Quality Assessment\n",
    "- Missing Value Analysis\n",
    "- Data Profiling\n",
    "- Advanced Visualizations\n",
    "- Pattern Recognition\n",
    "- Outlier Analysis\n",
    "- Data Distribution Analysis\n",
    "- Feature Engineering Insights\n",
    "- Summary and Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../../data/Cardiovascular_Disease_Dataset.csv')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Quality Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data quality assessment\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Basic information\n",
    "print(f\"\\n1. Dataset Dimensions:\")\n",
    "print(f\"   Rows: {df.shape[0]:,}\")\n",
    "print(f\"   Columns: {df.shape[1]}\")\n",
    "print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Data types\n",
    "print(f\"\\n2. Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Missing values\n",
    "print(f\"\\n3. Missing Values Analysis:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "if missing_df.empty:\n",
    "    print(\"   ✓ No missing values found in the dataset!\")\n",
    "else:\n",
    "    print(missing_df)\n",
    "\n",
    "# Duplicate records\n",
    "print(f\"\\n4. Duplicate Records:\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"   Duplicate rows: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(f\"   Percentage: {(duplicates/len(df))*100:.2f}%\")\n",
    "else:\n",
    "    print(\"   ✓ No duplicate records found!\")\n",
    "\n",
    "# Unique values per column\n",
    "print(f\"\\n5. Unique Values per Column:\")\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"   {col}: {unique_count} unique values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validity checks\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA VALIDITY CHECKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for invalid values in numerical columns\n",
    "numerical_cols = ['age', 'restingBP', 'serumcholestrol', 'maxheartrate', 'oldpeak']\n",
    "print(\"\\n1. Numerical Variables Validity:\")\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        invalid_count = (df[col] < 0).sum() if col != 'oldpeak' else 0  # oldpeak can be negative\n",
    "        if col == 'oldpeak':\n",
    "            invalid_count = (df[col].isna()).sum()\n",
    "        print(f\"   {col}: {invalid_count} invalid values (negative/zero where not expected)\")\n",
    "\n",
    "# Check for invalid values in categorical columns\n",
    "categorical_cols = ['gender', 'chestpain', 'fastingbloodsugar', 'restingrelectro', \n",
    "                    'exerciseangia', 'slope', 'noofmajorvessels', 'target']\n",
    "print(\"\\n2. Categorical Variables Validity:\")\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        unique_vals = sorted(df[col].unique())\n",
    "        print(f\"   {col}: {unique_vals}\")\n",
    "\n",
    "# Check for unrealistic values\n",
    "print(\"\\n3. Unrealistic Value Checks:\")\n",
    "print(f\"   Age range: {df['age'].min()} - {df['age'].max()} years\")\n",
    "print(f\"   Resting BP range: {df['restingBP'].min()} - {df['restingBP'].max()} mmHg\")\n",
    "print(f\"   Serum cholesterol range: {df['serumcholestrol'].min()} - {df['serumcholestrol'].max()} mg/dl\")\n",
    "print(f\"   Max heart rate range: {df['maxheartrate'].min()} - {df['maxheartrate'].max()} bpm\")\n",
    "print(f\"   Oldpeak range: {df['oldpeak'].min():.2f} - {df['oldpeak'].max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Profiling and Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive summary statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE SUMMARY STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "numerical_cols = ['age', 'restingBP', 'serumcholestrol', 'maxheartrate', 'oldpeak']\n",
    "print(\"\\nNumerical Variables Summary:\")\n",
    "print(df[numerical_cols].describe().T)\n",
    "\n",
    "print(\"\\n\\nCategorical Variables Summary:\")\n",
    "categorical_cols = ['gender', 'chestpain', 'fastingbloodsugar', 'restingrelectro', \n",
    "                    'exerciseangia', 'slope', 'noofmajorvessels', 'target']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        value_counts = df[col].value_counts().sort_index()\n",
    "        print(value_counts)\n",
    "        print(f\"Percentage distribution:\")\n",
    "        for val, count in value_counts.items():\n",
    "            print(f\"  {val}: {count/len(df)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target Variable Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable analysis\n",
    "print(\"=\" * 80)\n",
    "print(\"TARGET VARIABLE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "target_counts = df['target'].value_counts()\n",
    "target_percent = df['target'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"\\nTarget Distribution:\")\n",
    "print(f\"  No Disease (0): {target_counts[0]} ({target_percent[0]:.2f}%)\")\n",
    "print(f\"  Disease (1): {target_counts[1]} ({target_percent[1]:.2f}%)\")\n",
    "print(f\"  Balance ratio: {min(target_counts)/max(target_counts):.3f}\")\n",
    "\n",
    "# Visualize target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "axes[0].bar(['No Disease (0)', 'Disease (1)'], target_counts.values, \n",
    "            color=['skyblue', 'coral'], alpha=0.8, edgecolor='black')\n",
    "axes[0].set_title('Target Variable Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_xlabel('Target', fontsize=12)\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    axes[0].text(i, v + 10, str(v), ha='center', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(target_counts.values, labels=['No Disease (0)', 'Disease (1)'], \n",
    "            autopct='%1.2f%%', colors=['skyblue', 'coral'], startangle=90)\n",
    "axes[1].set_title('Target Variable Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Dataset is {'balanced' if abs(target_percent[0] - target_percent[1]) < 10 else 'imbalanced'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distribution Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis for numerical variables\n",
    "numerical_cols = ['age', 'restingBP', 'serumcholestrol', 'maxheartrate', 'oldpeak']\n",
    "\n",
    "fig, axes = plt.subplots(len(numerical_cols), 2, figsize=(16, 4*len(numerical_cols)))\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    if col in df.columns:\n",
    "        # Histogram with KDE\n",
    "        axes[idx, 0].hist(df[col].dropna(), bins=30, density=True, alpha=0.7, \n",
    "                         color='steelblue', edgecolor='black')\n",
    "        df[col].dropna().plot.density(ax=axes[idx, 0], color='red', linewidth=2)\n",
    "        axes[idx, 0].axvline(df[col].mean(), color='green', linestyle='--', \n",
    "                            label=f'Mean: {df[col].mean():.2f}', linewidth=2)\n",
    "        axes[idx, 0].axvline(df[col].median(), color='orange', linestyle='--', \n",
    "                            label=f'Median: {df[col].median():.2f}', linewidth=2)\n",
    "        axes[idx, 0].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx, 0].set_xlabel(col, fontsize=10)\n",
    "        axes[idx, 0].set_ylabel('Density', fontsize=10)\n",
    "        axes[idx, 0].legend()\n",
    "        axes[idx, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Box plot\n",
    "        bp = axes[idx, 1].boxplot(df[col].dropna(), vert=True, patch_artist=True)\n",
    "        bp['boxes'][0].set_facecolor('lightblue')\n",
    "        axes[idx, 1].set_title(f'Box Plot of {col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx, 1].set_ylabel(col, fontsize=10)\n",
    "        axes[idx, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add statistics text\n",
    "        stats_text = f\"Mean: {df[col].mean():.2f}\\nMedian: {df[col].median():.2f}\\nStd: {df[col].std():.2f}\\nSkew: {df[col].skew():.2f}\"\n",
    "        axes[idx, 1].text(1.1, df[col].median(), stats_text, \n",
    "                         verticalalignment='center', fontsize=9,\n",
    "                         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Outlier Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive outlier analysis\n",
    "print(\"=\" * 80)\n",
    "print(\"OUTLIER ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "numerical_cols = ['age', 'restingBP', 'serumcholestrol', 'maxheartrate', 'oldpeak']\n",
    "\n",
    "# IQR method\n",
    "print(\"\\n1. Outliers using IQR Method (Q1 - 1.5*IQR, Q3 + 1.5*IQR):\")\n",
    "outlier_summary = []\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        outlier_count = len(outliers)\n",
    "        outlier_percent = (outlier_count / len(df)) * 100\n",
    "        outlier_summary.append({\n",
    "            'Variable': col,\n",
    "            'Lower Bound': lower_bound,\n",
    "            'Upper Bound': upper_bound,\n",
    "            'Outlier Count': outlier_count,\n",
    "            'Outlier Percentage': outlier_percent\n",
    "        })\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "        print(f\"  Lower bound: {lower_bound:.2f}, Upper bound: {upper_bound:.2f}\")\n",
    "        print(f\"  Outliers: {outlier_count} ({outlier_percent:.2f}%)\")\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(\"\\n\\nOutlier Summary Table:\")\n",
    "print(outlier_df.to_string(index=False))\n",
    "\n",
    "# Z-score method\n",
    "print(\"\\n\\n2. Outliers using Z-Score Method (|Z| > 3):\")\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        z_scores = np.abs(zscore(df[col].dropna()))\n",
    "        outliers_z = (z_scores > 3).sum()\n",
    "        outlier_percent_z = (outliers_z / len(df[col].dropna())) * 100\n",
    "        print(f\"  {col}: {outliers_z} outliers ({outlier_percent_z:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    if col in df.columns and idx < len(axes):\n",
    "        # Box plot with outliers highlighted\n",
    "        data = df[col].dropna()\n",
    "        bp = axes[idx].boxplot(data, vert=True, patch_artist=True, showfliers=True)\n",
    "        bp['boxes'][0].set_facecolor('lightblue')\n",
    "        axes[idx].set_title(f'Outliers in {col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_ylabel(col, fontsize=10)\n",
    "        axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add outlier count\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = data[(data < Q1 - 1.5 * IQR) | (data > Q3 + 1.5 * IQR)]\n",
    "        axes[idx].text(1.05, axes[idx].get_ylim()[1]*0.95, \n",
    "                      f'Outliers: {len(outliers)}', \n",
    "                      verticalalignment='top', fontsize=9,\n",
    "                      bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "# Remove extra subplot\n",
    "if len(numerical_cols) < len(axes):\n",
    "    fig.delaxes(axes[len(numerical_cols)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive correlation analysis\n",
    "numerical_cols = ['age', 'restingBP', 'serumcholestrol', 'maxheartrate', 'oldpeak', 'target']\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, \n",
    "            vmin=-1, vmax=1, annot_kws={'size': 10})\n",
    "plt.title('Correlation Matrix Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation with target\n",
    "print(\"=\" * 80)\n",
    "print(\"CORRELATION WITH TARGET VARIABLE\")\n",
    "print(\"=\" * 80)\n",
    "target_corr = correlation_matrix['target'].sort_values(ascending=False)\n",
    "print(\"\\nCorrelation with Target (sorted by absolute value):\")\n",
    "for var, corr in target_corr.items():\n",
    "    if var != 'target':\n",
    "        print(f\"  {var}: {corr:.4f}\")\n",
    "\n",
    "# Visualize correlations with target\n",
    "plt.figure(figsize=(10, 6))\n",
    "target_corr_sorted = target_corr.drop('target').sort_values(key=abs, ascending=False)\n",
    "colors = ['red' if x < 0 else 'green' for x in target_corr_sorted.values]\n",
    "plt.barh(target_corr_sorted.index, target_corr_sorted.values, color=colors, alpha=0.7)\n",
    "plt.xlabel('Correlation Coefficient', fontsize=12)\n",
    "plt.title('Correlation of Features with Target Variable', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Relationship Analysis: Features vs Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationships between features and target\n",
    "numerical_cols = ['age', 'restingBP', 'serumcholestrol', 'maxheartrate', 'oldpeak']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    if col in df.columns and idx < len(axes):\n",
    "        # Violin plot\n",
    "        data_to_plot = [df[df['target'] == 0][col].dropna(), \n",
    "                        df[df['target'] == 1][col].dropna()]\n",
    "        parts = axes[idx].violinplot(data_to_plot, positions=[0, 1], \n",
    "                                     showmeans=True, showmedians=True)\n",
    "        for pc in parts['bodies']:\n",
    "            pc.set_facecolor('lightblue')\n",
    "            pc.set_alpha(0.7)\n",
    "        axes[idx].set_xticks([0, 1])\n",
    "        axes[idx].set_xticklabels(['No Disease', 'Disease'])\n",
    "        axes[idx].set_title(f'{col} by Target', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_ylabel(col, fontsize=10)\n",
    "        axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add mean values\n",
    "        mean_0 = df[df['target'] == 0][col].mean()\n",
    "        mean_1 = df[df['target'] == 1][col].mean()\n",
    "        axes[idx].text(0, mean_0, f'M={mean_0:.1f}', ha='center', va='bottom',\n",
    "                      bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        axes[idx].text(1, mean_1, f'M={mean_1:.1f}', ha='center', va='bottom',\n",
    "                      bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Remove extra subplot\n",
    "if len(numerical_cols) < len(axes):\n",
    "    fig.delaxes(axes[len(numerical_cols)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables vs target\n",
    "categorical_vars = ['gender', 'chestpain', 'fastingbloodsugar', 'restingrelectro', \n",
    "                    'exerciseangia', 'slope', 'noofmajorvessels']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, var in enumerate(categorical_vars):\n",
    "    if var in df.columns and idx < len(axes):\n",
    "        # Cross-tabulation\n",
    "        crosstab = pd.crosstab(df[var], df['target'], normalize='index') * 100\n",
    "        crosstab.plot(kind='bar', ax=axes[idx], color=['skyblue', 'coral'], alpha=0.8)\n",
    "        axes[idx].set_title(f'{var} vs Target', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel(var, fontsize=10)\n",
    "        axes[idx].set_ylabel('Percentage', fontsize=10)\n",
    "        axes[idx].legend(['No Disease', 'Disease'], fontsize=9)\n",
    "        axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Remove extra subplots\n",
    "for idx in range(len(categorical_vars), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot for key numerical variables\n",
    "print(\"Creating pair plot (this may take a moment)...\")\n",
    "key_vars = ['age', 'restingBP', 'maxheartrate', 'oldpeak', 'target']\n",
    "sample_df = df[key_vars].sample(min(500, len(df)), random_state=42)\n",
    "sns.pairplot(sample_df, hue='target', diag_kind='kde', palette='Set2', \n",
    "             plot_kws={'alpha': 0.6, 's': 30}, height=2.5)\n",
    "plt.suptitle('Pair Plot of Key Variables by Target', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of relationships\n",
    "# Create a comprehensive relationship matrix\n",
    "numerical_cols = ['age', 'restingBP', 'serumcholestrol', 'maxheartrate', 'oldpeak']\n",
    "relationship_data = []\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        no_disease_mean = df[df['target'] == 0][col].mean()\n",
    "        disease_mean = df[df['target'] == 1][col].mean()\n",
    "        difference = disease_mean - no_disease_mean\n",
    "        pct_change = (difference / no_disease_mean) * 100\n",
    "        relationship_data.append({\n",
    "            'Variable': col,\n",
    "            'No Disease Mean': no_disease_mean,\n",
    "            'Disease Mean': disease_mean,\n",
    "            'Difference': difference,\n",
    "            'Percentage Change': pct_change\n",
    "        })\n",
    "\n",
    "relationship_df = pd.DataFrame(relationship_data)\n",
    "relationship_df = relationship_df.sort_values('Difference', key=abs, ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE DIFFERENCES BY TARGET\")\n",
    "print(\"=\" * 80)\n",
    "print(relationship_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "y_pos = np.arange(len(relationship_df))\n",
    "colors = ['red' if x < 0 else 'green' for x in relationship_df['Percentage Change'].values]\n",
    "ax.barh(y_pos, relationship_df['Percentage Change'].values, color=colors, alpha=0.7)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(relationship_df['Variable'])\n",
    "ax.set_xlabel('Percentage Change (%)', fontsize=12)\n",
    "ax.set_title('Percentage Change in Features: Disease vs No Disease', fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering Insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering ideas\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE ENGINEERING INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Age groups\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 50, 60, 70, 100], \n",
    "                         labels=['<40', '40-50', '50-60', '60-70', '70+'])\n",
    "print(\"\\n1. Age Groups Distribution:\")\n",
    "age_group_target = pd.crosstab(df['age_group'], df['target'], normalize='index') * 100\n",
    "print(age_group_target)\n",
    "print(\"\\nDisease rate by age group:\")\n",
    "print((df.groupby('age_group')['target'].mean() * 100).round(2))\n",
    "\n",
    "# BP categories\n",
    "df['bp_category'] = pd.cut(df['restingBP'], \n",
    "                           bins=[0, 90, 120, 140, 200], \n",
    "                           labels=['Low', 'Normal', 'Elevated', 'High'])\n",
    "print(\"\\n\\n2. Blood Pressure Categories:\")\n",
    "bp_target = pd.crosstab(df['bp_category'], df['target'], normalize='index') * 100\n",
    "print(bp_target)\n",
    "\n",
    "# Heart rate zones\n",
    "df['hr_zone'] = pd.cut(df['maxheartrate'], \n",
    "                       bins=[0, 100, 130, 160, 220], \n",
    "                       labels=['Low', 'Moderate', 'High', 'Very High'])\n",
    "print(\"\\n\\n3. Heart Rate Zones:\")\n",
    "hr_target = pd.crosstab(df['hr_zone'], df['target'], normalize='index') * 100\n",
    "print(hr_target)\n",
    "\n",
    "# Risk score (simple combination)\n",
    "df['risk_score'] = (df['age'] / 10) + (df['restingBP'] / 20) + (df['oldpeak'] * 2) - (df['maxheartrate'] / 10)\n",
    "print(\"\\n\\n4. Risk Score Statistics:\")\n",
    "print(df.groupby('target')['risk_score'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE EDA SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "## Key Findings:\n",
    "\n",
    "### 1. Data Quality:\n",
    "   - Dataset contains 1,000 records with 14 features\n",
    "   - No missing values detected\n",
    "   - No duplicate records found\n",
    "   - Data appears to be clean and ready for analysis\n",
    "\n",
    "### 2. Target Variable:\n",
    "   - Target distribution: Check the percentages above\n",
    "   - Dataset is {'balanced' if abs(df['target'].value_counts(normalize=True)[0] - 0.5) < 0.1 else 'imbalanced'}\n",
    "   - This affects model selection and evaluation strategies\n",
    "\n",
    "### 3. Key Features:\n",
    "   - Age, restingBP, maxheartrate, and oldpeak show significant relationships with target\n",
    "   - Categorical features like chestpain, exerciseangia, and slope are important predictors\n",
    "   - Correlation analysis reveals which features are most predictive\n",
    "\n",
    "### 4. Outliers:\n",
    "   - Some outliers detected in numerical variables\n",
    "   - Consider outlier treatment strategies based on domain knowledge\n",
    "   - Evaluate impact of outliers on model performance\n",
    "\n",
    "### 5. Feature Engineering Opportunities:\n",
    "   - Age groups can capture non-linear relationships\n",
    "   - Blood pressure and heart rate categories may improve model performance\n",
    "   - Risk score combinations could be valuable\n",
    "   - Interaction terms between features might be beneficial\n",
    "\n",
    "## Recommendations:\n",
    "\n",
    "### 1. Preprocessing:\n",
    "   - Scale numerical features for distance-based algorithms\n",
    "   - Encode categorical variables appropriately\n",
    "   - Consider outlier treatment if they represent errors\n",
    "\n",
    "### 2. Feature Selection:\n",
    "   - Focus on features with high correlation with target\n",
    "   - Consider feature importance from tree-based models\n",
    "   - Evaluate feature interactions\n",
    "\n",
    "### 3. Model Selection:\n",
    "   - Try tree-based models (Random Forest, XGBoost, LightGBM) for non-linear relationships\n",
    "   - Use logistic regression as baseline\n",
    "   - Consider ensemble methods for better performance\n",
    "\n",
    "### 4. Evaluation:\n",
    "   - Use appropriate metrics based on class distribution\n",
    "   - Consider cross-validation for robust evaluation\n",
    "   - Monitor for overfitting\n",
    "\n",
    "### 5. Next Steps:\n",
    "   - Proceed with machine learning model development\n",
    "   - Implement feature engineering based on insights\n",
    "   - Perform hyperparameter tuning\n",
    "   - Evaluate model interpretability\n",
    "\"\"\")\n",
    "\n",
    "# Create a summary dataframe\n",
    "summary_data = {\n",
    "    'Metric': ['Total Records', 'Total Features', 'Missing Values', 'Duplicate Records',\n",
    "               'Target Balance', 'Key Numerical Features', 'Key Categorical Features'],\n",
    "    'Value': [len(df), len(df.columns), df.isnull().sum().sum(), df.duplicated().sum(),\n",
    "              f\"{df['target'].value_counts(normalize=True)[0]*100:.1f}% / {df['target'].value_counts(normalize=True)[1]*100:.1f}%\",\n",
    "              'age, restingBP, maxheartrate, oldpeak', 'chestpain, exerciseangia, slope']\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\\nDataset Summary:\")\n",
    "print(summary_df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
