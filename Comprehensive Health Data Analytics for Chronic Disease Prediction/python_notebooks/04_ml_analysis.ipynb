{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning Analysis\n",
        "\n",
        "## Overview\n",
        "This notebook implements multiple machine learning algorithms to predict cardiovascular disease:\n",
        "- Logistic Regression\n",
        "- Random Forest\n",
        "- Gradient Boosting\n",
        "- XGBoost\n",
        "- LightGBM\n",
        "- Support Vector Machine (SVM)\n",
        "\n",
        "The models are evaluated using ROC-AUC score, confusion matrix, and classification reports.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and prepare data\n",
        "df = pd.read_csv('../data/health_data.csv')\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# Feature engineering\n",
        "df['age_years'] = df['age'] / 365.25\n",
        "df['bmi'] = df['weight'] / ((df['height'] / 100) ** 2)\n",
        "\n",
        "# Data cleaning\n",
        "df = df[(df['ap_hi'] >= 80) & (df['ap_hi'] <= 250)]\n",
        "df = df[(df['ap_lo'] >= 40) & (df['ap_lo'] <= 150)]\n",
        "df = df[df['ap_hi'] >= df['ap_lo']]\n",
        "df = df[(df['height'] >= 100) & (df['height'] <= 220)]\n",
        "df = df[(df['weight'] >= 30) & (df['weight'] <= 200)]\n",
        "df = df[(df['bmi'] >= 10) & (df['bmi'] <= 60)]\n",
        "\n",
        "# Select features\n",
        "feature_cols = ['age_years', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', \n",
        "                'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'bmi']\n",
        "X = df[feature_cols]\n",
        "y = df['cardio']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n",
        "print(f\"Features: {feature_cols}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss'),\n",
        "    'LightGBM': LGBMClassifier(random_state=42, verbose=-1),\n",
        "    'SVM': SVC(probability=True, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Train models\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    \n",
        "    if name in ['Logistic Regression', 'SVM']:\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "    \n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba,\n",
        "        'roc_auc': roc_auc,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std()\n",
        "    }\n",
        "    \n",
        "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
        "    print(f\"  CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification reports\n",
        "for name, result in results.items():\n",
        "    print(f\"{name} - Classification Report:\")\n",
        "    print(classification_report(y_test, result['y_pred']))\n",
        "    print()\n",
        "\n",
        "# ROC curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "for name, result in results.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, result['y_pred_proba'])\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {result[\"roc_auc\"]:.4f})', linewidth=2)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('ROC Curves - Model Comparison', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc='lower right', fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/roc_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Model comparison\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(results.keys()),\n",
        "    'ROC-AUC': [r['roc_auc'] for r in results.values()],\n",
        "    'CV Mean': [r['cv_mean'] for r in results.values()],\n",
        "    'CV Std': [r['cv_std'] for r in results.values()]\n",
        "}).sort_values('ROC-AUC', ascending=False)\n",
        "\n",
        "print(\"Model Comparison:\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(comparison_df['Model'], comparison_df['ROC-AUC'], color='steelblue', edgecolor='black')\n",
        "plt.xlabel('ROC-AUC Score', fontsize=12)\n",
        "plt.ylabel('Model', fontsize=12)\n",
        "plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "plt.xlim(0.5, 1.0)\n",
        "for i, v in enumerate(comparison_df['ROC-AUC']):\n",
        "    plt.text(v + 0.01, i, f'{v:.4f}', va='center', fontweight='bold')\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance from tree-based models\n",
        "tree_models = ['Random Forest', 'Gradient Boosting', 'XGBoost', 'LightGBM']\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, name in enumerate(tree_models):\n",
        "    if name in results:\n",
        "        model = results[name]['model']\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            importances = model.feature_importances_\n",
        "            indices = np.argsort(importances)[::-1]\n",
        "            \n",
        "            axes[i].barh(range(len(feature_cols)), importances[indices], \n",
        "                        color='steelblue', edgecolor='black')\n",
        "            axes[i].set_yticks(range(len(feature_cols)))\n",
        "            axes[i].set_yticklabels([feature_cols[j] for j in indices])\n",
        "            axes[i].set_xlabel('Importance', fontsize=10)\n",
        "            axes[i].set_title(f'{name} - Feature Importance', fontsize=12, fontweight='bold')\n",
        "            axes[i].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
