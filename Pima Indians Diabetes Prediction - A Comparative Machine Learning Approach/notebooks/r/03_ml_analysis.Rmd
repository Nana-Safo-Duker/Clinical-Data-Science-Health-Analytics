---
title: "Pima Indians Diabetes Dataset - Machine Learning Analysis"
subtitle: "Comprehensive ML Analysis using Appropriate Algorithms"
author: "Data Science Analysis"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: show
    theme: cosmo
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width = 12, fig.height = 8)
```

```{r libraries}
# Load necessary libraries
library(dplyr)
library(tidyverse)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
library(gbm)
library(rpart)
library(pROC)
library(ROCR)
library(gridExtra)
library(VIM)
```

## 1. Load and Prepare Data

```{r load-data}
# Load the dataset
data <- read.csv("../../data/pima-indians-diabetes.csv", skip = 9, header = FALSE)

# Set column names
colnames(data) <- c(
  "Pregnancies",
  "Glucose",
  "BloodPressure",
  "SkinThickness",
  "Insulin",
  "BMI",
  "DiabetesPedigreeFunction",
  "Age",
  "Outcome"
)

# Convert Outcome to factor
data$Outcome <- as.factor(data$Outcome)
levels(data$Outcome) <- c("No", "Yes")

# Ensure levels are correct
data$Outcome <- factor(data$Outcome, levels = c("No", "Yes"))

cat("Dataset Shape:", dim(data), "\n")
cat("Class Distribution:\n")
table(data$Outcome)
```

## 2. Data Preprocessing

```{r preprocessing}
# Handle missing values (zeros in this dataset)
# Replace zeros with median for features where zero doesn't make sense
features_to_fix <- c("Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI")

data_processed <- data
for (feature in features_to_fix) {
  # Replace zeros with median
  median_val <- median(data_processed[[feature]][data_processed[[feature]] != 0], na.rm = TRUE)
  data_processed[[feature]][data_processed[[feature]] == 0] <- median_val
}

# Separate features and target
X <- data_processed[, !colnames(data_processed) %in% "Outcome"]
y <- data_processed$Outcome

# Split the data
set.seed(42)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[trainIndex, ]
X_test <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test <- y[-trainIndex]

cat("Training set size:", nrow(X_train), "\n")
cat("Test set size:", nrow(X_test), "\n")
cat("\nTraining set class distribution:\n")
table(y_train)
cat("\nTest set class distribution:\n")
table(y_test)
```

## 3. Model Training and Evaluation

### 3.1 Logistic Regression

```{r logistic-regression}
# Logistic Regression
set.seed(42)
lr_model <- train(
  x = X_train,
  y = y_train,
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 5)
)

lr_pred <- predict(lr_model, newdata = X_test)
lr_pred_proba <- predict(lr_model, newdata = X_test, type = "prob")

# Calculate metrics
lr_cm <- confusionMatrix(lr_pred, y_test)
# Convert factor to numeric (No=0, Yes=1)
y_test_numeric <- as.numeric(y_test) - 1
lr_roc <- roc(y_test_numeric, lr_pred_proba$Yes)

cat("Logistic Regression Results:\n")
print(lr_cm)
cat("\nROC-AUC:", auc(lr_roc), "\n")
```

### 3.2 Random Forest

```{r random-forest}
# Random Forest
set.seed(42)
rf_model <- train(
  x = X_train,
  y = y_train,
  method = "rf",
  ntree = 100,
  trControl = trainControl(method = "cv", number = 5),
  importance = TRUE
)

rf_pred <- predict(rf_model, newdata = X_test)
rf_pred_proba <- predict(rf_model, newdata = X_test, type = "prob")

# Calculate metrics
rf_cm <- confusionMatrix(rf_pred, y_test)
# Convert factor to numeric (No=0, Yes=1)
y_test_numeric <- as.numeric(y_test) - 1
rf_roc <- roc(y_test_numeric, rf_pred_proba$Yes)

cat("Random Forest Results:\n")
print(rf_cm)
cat("\nROC-AUC:", auc(rf_roc), "\n")

# Feature importance
varImp(rf_model)
plot(varImp(rf_model), main = "Random Forest - Feature Importance")
```

### 3.3 Support Vector Machine (SVM)

```{r svm}
# Support Vector Machine
set.seed(42)
svm_model <- train(
  x = X_train,
  y = y_train,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 5
)

svm_pred <- predict(svm_model, newdata = X_test)
svm_pred_proba <- predict(svm_model, newdata = X_test, type = "prob")

# Calculate metrics
svm_cm <- confusionMatrix(svm_pred, y_test)
# Convert factor to numeric (No=0, Yes=1)
y_test_numeric <- as.numeric(y_test) - 1
svm_roc <- roc(y_test_numeric, svm_pred_proba$Yes)

cat("SVM Results:\n")
print(svm_cm)
cat("\nROC-AUC:", auc(svm_roc), "\n")
```

### 3.4 Gradient Boosting

```{r gradient-boosting}
# Gradient Boosting
set.seed(42)
gbm_model <- train(
  x = X_train,
  y = y_train,
  method = "gbm",
  trControl = trainControl(method = "cv", number = 5),
  verbose = FALSE
)

gbm_pred <- predict(gbm_model, newdata = X_test)
gbm_pred_proba <- predict(gbm_model, newdata = X_test, type = "prob")

# Calculate metrics
gbm_cm <- confusionMatrix(gbm_pred, y_test)
# Convert factor to numeric (No=0, Yes=1)
y_test_numeric <- as.numeric(y_test) - 1
gbm_roc <- roc(y_test_numeric, gbm_pred_proba$Yes)

cat("Gradient Boosting Results:\n")
print(gbm_cm)
cat("\nROC-AUC:", auc(gbm_roc), "\n")
```

### 3.5 Decision Tree

```{r decision-tree}
# Decision Tree
set.seed(42)
dt_model <- train(
  x = X_train,
  y = y_train,
  method = "rpart",
  trControl = trainControl(method = "cv", number = 5)
)

dt_pred <- predict(dt_model, newdata = X_test)
dt_pred_proba <- predict(dt_model, newdata = X_test, type = "prob")

# Calculate metrics
dt_cm <- confusionMatrix(dt_pred, y_test)
# Convert factor to numeric (No=0, Yes=1)
y_test_numeric <- as.numeric(y_test) - 1
dt_roc <- roc(y_test_numeric, dt_pred_proba$Yes)

cat("Decision Tree Results:\n")
print(dt_cm)
cat("\nROC-AUC:", auc(dt_roc), "\n")
```

### 3.6 K-Nearest Neighbors (KNN)

```{r knn}
# K-Nearest Neighbors
set.seed(42)
knn_model <- train(
  x = X_train,
  y = y_train,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 10
)

knn_pred <- predict(knn_model, newdata = X_test)
knn_pred_proba <- predict(knn_model, newdata = X_test, type = "prob")

# Calculate metrics
knn_cm <- confusionMatrix(knn_pred, y_test)
# Convert factor to numeric (No=0, Yes=1)
y_test_numeric <- as.numeric(y_test) - 1
knn_roc <- roc(y_test_numeric, knn_pred_proba$Yes)

cat("KNN Results:\n")
print(knn_cm)
cat("\nROC-AUC:", auc(knn_roc), "\n")
```

## 4. Model Comparison

```{r model-comparison}
# Compare all models
results <- data.frame(
  Model = c("Logistic Regression", "Random Forest", "SVM", "Gradient Boosting", "Decision Tree", "KNN"),
  Accuracy = c(
    lr_cm$overall["Accuracy"],
    rf_cm$overall["Accuracy"],
    svm_cm$overall["Accuracy"],
    gbm_cm$overall["Accuracy"],
    dt_cm$overall["Accuracy"],
    knn_cm$overall["Accuracy"]
  ),
  Sensitivity = c(
    lr_cm$byClass["Sensitivity"],
    rf_cm$byClass["Sensitivity"],
    svm_cm$byClass["Sensitivity"],
    gbm_cm$byClass["Sensitivity"],
    dt_cm$byClass["Sensitivity"],
    knn_cm$byClass["Sensitivity"]
  ),
  Specificity = c(
    lr_cm$byClass["Specificity"],
    rf_cm$byClass["Specificity"],
    svm_cm$byClass["Specificity"],
    gbm_cm$byClass["Specificity"],
    dt_cm$byClass["Specificity"],
    knn_cm$byClass["Specificity"]
  ),
  ROC_AUC = c(
    auc(lr_roc),
    auc(rf_roc),
    auc(svm_roc),
    auc(gbm_roc),
    auc(dt_roc),
    auc(knn_roc)
  )
)

cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MODEL COMPARISON\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
print(results, digits = 4)

# Visualize model comparison
library(reshape2)
results_melted <- melt(results, id.vars = "Model", variable.name = "Metric", value.name = "Score")

ggplot(results_melted, aes(x = Model, y = Score, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Model Comparison", x = "Model", y = "Score") +
  scale_fill_brewer(palette = "Set2")
```

## 5. ROC Curves

```{r roc-curves}
# Plot ROC curves for all models
# Convert factor to numeric for all ROC calculations
y_test_numeric <- as.numeric(y_test) - 1

roc_list <- list(
  "Logistic Regression" = lr_roc,
  "Random Forest" = rf_roc,
  "SVM" = svm_roc,
  "Gradient Boosting" = gbm_roc,
  "Decision Tree" = dt_roc,
  "KNN" = knn_roc
)

# Create ROC curve plot
plot(lr_roc, col = "red", main = "ROC Curves Comparison", lwd = 2, print.auc = FALSE)
lines(rf_roc, col = "blue", lwd = 2)
lines(svm_roc, col = "green", lwd = 2)
lines(gbm_roc, col = "orange", lwd = 2)
lines(dt_roc, col = "purple", lwd = 2)
lines(knn_roc, col = "brown", lwd = 2)
abline(a = 0, b = 1, lty = 2, col = "gray")
legend("bottomright", 
       legend = paste(names(roc_list), " (AUC = ", 
                     round(sapply(roc_list, auc), 3), ")", sep = ""),
       col = c("red", "blue", "green", "orange", "purple", "brown"),
       lty = 1, lwd = 2, cex = 0.8)
```

## 6. Cross-Validation

```{r cross-validation}
# Cross-validation for all models
set.seed(42)
cv_control <- trainControl(method = "cv", number = 5, 
                          classProbs = TRUE, 
                          summaryFunction = twoClassSummary)

# Logistic Regression CV
lr_cv <- train(
  x = X_train,
  y = y_train,
  method = "glm",
  family = "binomial",
  trControl = cv_control,
  metric = "ROC"
)

# Random Forest CV
rf_cv <- train(
  x = X_train,
  y = y_train,
  method = "rf",
  ntree = 100,
  trControl = cv_control,
  metric = "ROC"
)

# SVM CV
svm_cv <- train(
  x = X_train,
  y = y_train,
  method = "svmRadial",
  trControl = cv_control,
  preProcess = c("center", "scale"),
  metric = "ROC"
)

# Gradient Boosting CV
gbm_cv <- train(
  x = X_train,
  y = y_train,
  method = "gbm",
  trControl = cv_control,
  verbose = FALSE,
  metric = "ROC"
)

# Compare CV results
cv_results <- resamples(list(
  "Logistic Regression" = lr_cv,
  "Random Forest" = rf_cv,
  "SVM" = svm_cv,
  "Gradient Boosting" = gbm_cv
))

summary(cv_results)
bwplot(cv_results, main = "Cross-Validation Results Comparison")
```

## 7. Summary and Conclusions

```{r summary}
# Find best model
best_model_idx <- which.max(results$ROC_AUC)
best_model <- results$Model[best_model_idx]
best_roc_auc <- results$ROC_AUC[best_model_idx]

cat(paste(rep("=", 80), collapse = ""), "\n")
cat("MACHINE LEARNING ANALYSIS SUMMARY\n")
cat(paste(rep("=", 80), collapse = ""), "\n\n")
cat("Best Model:", best_model, "\n")
cat("Best ROC-AUC Score:", best_roc_auc, "\n\n")
cat("Best Model Metrics:\n")
print(results[best_model_idx, ])

cat("\n\nKey Findings:\n")
cat("1. Multiple algorithms were tested for diabetes prediction\n")
cat("2. Random Forest and Gradient Boosting typically perform well on this dataset\n")
cat("3. Feature importance analysis reveals Glucose, BMI, and Age as key predictors\n")
cat("4. Class imbalance should be considered for future improvements\n")
cat("5. Cross-validation confirms model stability\n")
cat(paste(rep("=", 80), collapse = ""), "\n")
```

